{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk.disaggregate import Disaggregator\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The NILMTK API has some methods already implemented. But its value comes from enabling us to develop our methods and use them on their framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this example I will show you how to implement a simple SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first thing we need is to create a class that inherits from the Disaggregator class and has 4 methods\n",
    "#### You can find bellow the complete class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Svm(Disaggregator):\n",
    "    def __init__(self, params):\n",
    "\n",
    "    def partial_fit(self, train_main, train_appliances, **load_kwargs):\n",
    "        ##TODO\n",
    "                        \n",
    "    def disaggregate_chunk(self, test_mains):\n",
    "        ##TODO\n",
    "\n",
    "    def save_model(self, folder_name):\n",
    "        ##TODO\n",
    "\n",
    "    def load_model(self, folder_name):\n",
    "        ##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the  __ init__  we receive the params argument which is a dictionary with all the information needed for our model.\n",
    "In our case we don't need any information as our model will do a grid search for the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self, params):\n",
    "        self.model = {}\n",
    "        self.MODEL_NAME = 'SVM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The partial_fit method is called to train the algorithm. \n",
    "#### The train_main contains the aggregated energy recorded on the datasets  chosen.\n",
    "#### The train_appliances contains the energy recorded for the appliances in the datasets chosen\n",
    "#### The load_kwargs represent aditional arguments.\n",
    "\n",
    "In this example we use only the apparent power from the first house to train the SVM.\n",
    "\n",
    "Note: We train for each appliance a SVM and also save the best in the \"model\" dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def partial_fit(self, train_main, train_appliances, **load_kwargs):\n",
    "        x_train = train_main[0][\"power\"][\"apparent\"]    \n",
    "        x_train = np.reshape( x_train.values, (np.size(x_train.values), 1) )\n",
    "\n",
    "        for app_name, power in train_appliances:\n",
    "            print(\"Training \", app_name, \" in \", self.MODEL_NAME, \" model\\n\", end=\"\\r\")\n",
    "            \n",
    "            y_train = power[0][\"power\"][\"apparent\"].values\n",
    "            svm = SVR()\n",
    "\n",
    "            param = [\n",
    "                {\n",
    "                    \"kernel\": [\"rbf\"],\n",
    "                    \"C\": [0.03, 0.1, 0.3, 1]\n",
    "                }\n",
    "            ]\n",
    "            clf = GridSearchCV(svm, param, cv=5, n_jobs=20, verbose=2)\n",
    "            clf.fit(x_train, y_train)\n",
    "            rbf = (clf.best_estimator_, clf.best_score_)\n",
    "            \n",
    "            param = [\n",
    "                {\n",
    "                    \"kernel\": [\"poly\"],\n",
    "                    \"degree\": [2, 3, 4],\n",
    "                    \"C\": [0.03, 0.1, 0.3, 1]\n",
    "                }\n",
    "            ]\n",
    "            clf = GridSearchCV(svm, param, cv=5, n_jobs=20, verbose=2)\n",
    "            clf.fit(x_train, y_train)\n",
    "            poly = (clf.best_estimator_, clf.best_score_)\n",
    "\n",
    "            if rbf[1] > poly[1]:\n",
    "                print(rbf[0])\n",
    "                self.model[app_name] = rbf[0]\n",
    "            else:\n",
    "                print(poly[0])\n",
    "                self.model[app_name] = poly[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The disaggregate_chunk method is called when testing the algorithms.\n",
    "#### This method only receivs the aggregated data of the datasets.\n",
    "#### In this example we test the first building apparent power for each appliance.\n",
    "#### The results are then saved  in a pandas Dataframe and returned to the general program for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def disaggregate_chunk(self, test_mains):\n",
    "        test_predictions_list = []\n",
    "        x_test = test_mains[0][\"power\"][\"apparent\"]\n",
    "        x_test = np.reshape( x_test.values, (np.size(x_test.values), 1) )\n",
    "\n",
    "        appliance_powers_dict = {}\n",
    "\n",
    "        for i, app_name in enumerate(self.model):\n",
    "\n",
    "            print(\"Estimating power demand for '{}' in '{}'\\n\".format(app_name, self.MODEL_NAME))\n",
    "            pred = self.model[app_name].predict(x_test)\n",
    "            \n",
    "            column = pd.Series(\n",
    "                    pred, index=test_mains[0].index, name=i)\n",
    "            appliance_powers_dict[app_name] = column\n",
    "            \n",
    "        appliance_powers = pd.DataFrame(\n",
    "                appliance_powers_dict, dtype='float32')\n",
    "        test_predictions_list.append(appliance_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The save_model and load_model are self explanatory.\n",
    "#### In this methods we save and load a model to/from a file in the given repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bellow we can find the complete class ready to run. \n",
    "#### (only using 1 building and the apparent power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Svm(Disaggregator):\n",
    "    def __init__(self, params):\n",
    "        self.model = {}\n",
    "        self.MODEL_NAME = 'SVM'\n",
    "\n",
    "    def partial_fit(self, train_main, train_appliances, **load_kwargs):\n",
    "        x_train = train_main[0][\"power\"][\"apparent\"]    \n",
    "        x_train = np.reshape( x_train.values, (np.size(x_train.values), 1) )\n",
    "\n",
    "        for app_name, power in train_appliances:\n",
    "            print(\"Training \", app_name, \" in \", self.MODEL_NAME, \" model\\n\", end=\"\\r\")\n",
    "            \n",
    "            y_train = power[0][\"power\"][\"apparent\"].values\n",
    "            svm = SVR()\n",
    "\n",
    "            param = [\n",
    "                {\n",
    "                    \"kernel\": [\"rbf\"],\n",
    "                    \"C\": [0.03, 0.1, 0.3, 1]\n",
    "                }\n",
    "            ]\n",
    "            clf = GridSearchCV(svm, param, cv=5, n_jobs=20, verbose=2)\n",
    "            clf.fit(x_train, y_train)\n",
    "            rbf = (clf.best_estimator_, clf.best_score_)\n",
    "            \n",
    "            param = [\n",
    "                {\n",
    "                    \"kernel\": [\"poly\"],\n",
    "                    \"degree\": [2, 3, 4],\n",
    "                    \"C\": [0.03, 0.1, 0.3, 1]\n",
    "                }\n",
    "            ]\n",
    "            clf = GridSearchCV(svm, param, cv=5, n_jobs=20, verbose=2)\n",
    "            clf.fit(x_train, y_train)\n",
    "            poly = (clf.best_estimator_, clf.best_score_)\n",
    "\n",
    "            if rbf[1] > poly[1]:\n",
    "                print(rbf[0])\n",
    "                self.model[app_name] = rbf[0]\n",
    "            else:\n",
    "                print(poly[0])\n",
    "                self.model[app_name] = poly[0]\n",
    "                        \n",
    "    def disaggregate_chunk(self, test_mains):\n",
    "        test_predictions_list = []\n",
    "        x_test = test_mains[0][\"power\"][\"apparent\"]\n",
    "        x_test = np.reshape( x_test.values, (np.size(x_test.values), 1) )\n",
    "\n",
    "        appliance_powers_dict = {}\n",
    "\n",
    "        for i, app_name in enumerate(self.model):\n",
    "\n",
    "            print(\"Estimating power demand for '{}' in '{}'\\n\".format(app_name, self.MODEL_NAME))\n",
    "            pred = self.model[app_name].predict(x_test)\n",
    "            \n",
    "            column = pd.Series(\n",
    "                    pred, index=test_mains[0].index, name=i)\n",
    "            appliance_powers_dict[app_name] = column\n",
    "            \n",
    "        appliance_powers = pd.DataFrame(\n",
    "                appliance_powers_dict, dtype='float32')\n",
    "        test_predictions_list.append(appliance_powers)\n",
    "\n",
    "        return test_predictions_list\n",
    "\n",
    "    def save_model(self, folder_name):\n",
    "        string_to_save = json.dumps(self.model)\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        with open(os.path.join(folder_name, \"model.txt\"), \"w\") as f:\n",
    "            f.write(string_to_save)\n",
    "\n",
    "    def load_model(self, folder_name):\n",
    "        with open(os.path.join(folder_name, \"model.txt\"), \"r\") as f:\n",
    "            model_string = f.read().strip()\n",
    "            self.model = json.loads(model_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
